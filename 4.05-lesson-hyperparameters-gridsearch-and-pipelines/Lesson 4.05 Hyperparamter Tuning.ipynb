{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a12ce61",
   "metadata": {},
   "source": [
    "# Lesson 4.05 - Hyperparameter Tuning\n",
    "\n",
    "#### What is the difference between hyperparameters and statistical parameters?\n",
    "    \n",
    "- Statistical parameters are quantities that a model can learn or estimate. Examples include $\\beta_0$ and $\\beta_1$ in a linear model.\n",
    "- Hyperparameters are quantities our model cannot learn, but affect the fit of our model. Examples include $k$ in $k$-nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef5f4388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d55c5c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/modifiedIris2Classes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25bfb8ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113255e4",
   "metadata": {},
   "source": [
    "## Splitting Data into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbfb92fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[['petal length (cm)']], df['target'], random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b399dca6",
   "metadata": {},
   "source": [
    "## Standardize the Data\n",
    "Logistic Regression is impacted by scale so you need to scale the features in the data before using Logistic Regresison.  \n",
    "\n",
    "Scikit-Learn's `StandardScaler` helps standardize the datasetâ€™s features for better performance by changing the values so that the distribution standard deviation from the mean equals one. More info can be found [here](https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbb12b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training set only.\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695fef4a",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1238ad3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate KNN with default k value of 3\n",
    "classifier = KNeighborsClassifier(n_neighbors = 3)\n",
    "classifier.fit(X_train, y_train)\n",
    "classifier_y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "107ff19a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9  4]\n",
      " [ 0 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.69      0.82        13\n",
      "           1       0.75      1.00      0.86        12\n",
      "\n",
      "    accuracy                           0.84        25\n",
      "   macro avg       0.88      0.85      0.84        25\n",
      "weighted avg       0.88      0.84      0.84        25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, classifier_y_pred))\n",
    "print(classification_report(y_test, classifier_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4fb96f",
   "metadata": {},
   "source": [
    "## What are \"hyperparameters?\"\n",
    "\n",
    "1. Built-in quantities of models that we can use to fine-tune our results. For example what value of $k$ do we select?\n",
    "\n",
    "2. These are quantities our model **cannot** learn... **we must decide on these ourselves**!\n",
    "\n",
    "3. These are different from statistical parameters, which are quantities a model _can_ learn.\n",
    "\n",
    "4. Different values for hyperparameters can result in substantially different models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185d1800",
   "metadata": {},
   "source": [
    "## GridSearch\n",
    "**One method of searching for the optimal set of hyperparameters is called GridSearch.**\n",
    "\n",
    "1. GridSearch gets its name from the fact that we are searching over a \"grid\" of hyperparameters. \n",
    "2. For example, imagine the `n_neighbors` hyperparameters as the columns and `weightings` as the rows. This makes a grid.\n",
    "3. We check the accuracy for all combinations of hyperparameters on the grid.\n",
    "\n",
    "#### More information on GridSearch's functionality and limitations can be found at this [link](https://towardsdatascience.com/gridsearchcv-for-beginners-db48a90114ee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a4c0332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up experiment with taining and test data for X and Y values\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(df[['petal length (cm)']], df['target'], random_state=0)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train2)\n",
    "X_train2 = scaler.transform(X_train2)\n",
    "X_test2 = scaler.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75687ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate Basic Knn with initial k value\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84e9c1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate and display mean accuracy of Basic Knn on test data\n",
    "knn.score(X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b435b022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Gridsearch with preferred n_neighbours range and preferred CV value\n",
    "params = {\"n_neighbors\":[3,4,5,6,7,8,9,10]}\n",
    "model = GridSearchCV(knn, params, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "581d3201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 9}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train2, y_train2)\n",
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "631ba0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate / Display best mean cross-validated accuracy achieved.\n",
    "# Note: Model score was established based on training subset (not full data)\n",
    "model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b43be5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=9)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Knn with 9 neighbors\n",
    "gridsearch_knn = KNeighborsClassifier(n_neighbors = 9)\n",
    "gridsearch_knn.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbb121fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 0 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "gridsearch_y_pred = gridsearch_knn.predict(X_test2)\n",
    "print(gridsearch_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efff8b49",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  3]\n",
      " [ 0 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.77      0.87        13\n",
      "           1       0.80      1.00      0.89        12\n",
      "\n",
      "    accuracy                           0.88        25\n",
      "   macro avg       0.90      0.88      0.88        25\n",
      "weighted avg       0.90      0.88      0.88        25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test2, gridsearch_y_pred))\n",
    "print(classification_report(y_test2, gridsearch_y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
